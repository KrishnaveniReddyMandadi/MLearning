{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "333ce19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.ensemble import BaggingClassifier as bagging\n",
    "from sklearn.ensemble import AdaBoostClassifier as adaboost\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from numpy import mean, std\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris_data = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d89eb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_data.data\n",
    "y = iris_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "06900732",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8841474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging model score using 1 estimators: 0.7631578947368421\n",
      "Bagging model score using 2 estimators: 0.5789473684210527\n",
      "Bagging model score using 3 estimators: 0.5789473684210527\n",
      "Bagging model score using 4 estimators: 0.8947368421052632\n",
      "Bagging model score using 5 estimators: 0.8947368421052632\n",
      "Bagging model score using 6 estimators: 0.8947368421052632\n",
      "Bagging model score using 7 estimators: 0.9736842105263158\n",
      "Bagging model score using 8 estimators: 0.9736842105263158\n",
      "Bagging model score using 9 estimators: 0.9736842105263158\n",
      "Bagging model score using 10 estimators: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "for c in range(1, 11):\n",
    "    bagging_model = bagging(DecisionTreeClassifier(max_depth = 1), n_estimators = c, random_state = 0).fit(X_train, y_train)\n",
    "    bagging_model_predictions = bagging_model.predict(X_test)\n",
    "    bagging_model_accuracy = accuracy_score(bagging_model_predictions, y_test)\n",
    "    print(\"Bagging model score using \" +str(c)+\" estimators: \" +str(bagging_model_accuracy))\n",
    "    accuracy.append(bagging_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9dd663eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada boost model score using 1 estimators: 0.5789473684210527\n",
      "ada boost model score using 2 estimators: 0.8947368421052632\n",
      "ada boost model score using 3 estimators: 0.8947368421052632\n",
      "ada boost model score using 4 estimators: 0.9736842105263158\n",
      "ada boost model score using 5 estimators: 0.9736842105263158\n",
      "ada boost model score using 6 estimators: 0.8947368421052632\n",
      "ada boost model score using 7 estimators: 0.8947368421052632\n",
      "ada boost model score using 8 estimators: 0.9736842105263158\n",
      "ada boost model score using 9 estimators: 0.9736842105263158\n",
      "ada boost model score using 10 estimators: 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = []\n",
    "for d in range(1, 11):\n",
    "    ada_model = adaboost(DecisionTreeClassifier(max_depth = 1), n_estimators = d, random_state = 0).fit(X_train, y_train)\n",
    "    ada_model_predictions = ada_model.predict(X_test)\n",
    "    ada_model_accuracy = accuracy_score(ada_model_predictions, y_test)\n",
    "    print(\"ada boost model score using \" +str(d)+\" estimators: \" +str(ada_model_accuracy))\n",
    "    accuracy1.append(ada_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1965a",
   "metadata": {},
   "source": [
    "The accuracy of the bagging classifier increased intially and was maintained contstant by increasing the number of estimators. Increasing the number of estimators in the boosting classifier caused an early fluctuation in the model's score. However, the final score was found to be a factor of 0.08 lower than when only one estimator was utilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9f6ec517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estmators = 1, 'Accuracy: 0.640, 0.025'\n",
      "n_estmators = 2, 'Accuracy: 0.860, 0.169'\n",
      "n_estmators = 3, 'Accuracy: 0.927, 0.053'\n",
      "n_estmators = 4, 'Accuracy: 0.927, 0.053'\n",
      "n_estmators = 5, 'Accuracy: 0.927, 0.053'\n",
      "n_estmators = 6, 'Accuracy: 0.927, 0.053'\n",
      "n_estmators = 7, 'Accuracy: 0.927, 0.053'\n",
      "n_estmators = 8, 'Accuracy: 0.927, 0.053'\n",
      "n_estmators = 9, 'Accuracy: 0.927, 0.053'\n",
      "n_estmators = 10, 'Accuracy: 0.927, 0.053'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_bag = []\n",
    "for j in range(1, 11):\n",
    "    bagclassfifier = bagging(DecisionTreeClassifier(max_depth = 1).fit(X_train,y_train), n_estimators= j, random_state = 0) \n",
    "    scores = cross_val_score( bagclassfifier, X, y, cv = 5)\n",
    "    print(\"n_estmators = %d, 'Accuracy: %.3f, %.3f'\" % (j, mean(scores), std(scores)))\n",
    "    accuracy_bag.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7cfcedbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estmators = 1, 'Accuracy: 0.667, 0.000'\n",
      "n_estmators = 2, 'Accuracy: 0.947, 0.034'\n",
      "n_estmators = 3, 'Accuracy: 0.947, 0.034'\n",
      "n_estmators = 4, 'Accuracy: 0.953, 0.027'\n",
      "n_estmators = 5, 'Accuracy: 0.953, 0.027'\n",
      "n_estmators = 6, 'Accuracy: 0.887, 0.115'\n",
      "n_estmators = 7, 'Accuracy: 0.840, 0.145'\n",
      "n_estmators = 8, 'Accuracy: 0.900, 0.119'\n",
      "n_estmators = 9, 'Accuracy: 0.953, 0.027'\n",
      "n_estmators = 10, 'Accuracy: 0.947, 0.034'\n"
     ]
    }
   ],
   "source": [
    "accuracy_ada = []\n",
    "for i in range(1, 11):\n",
    "    adaclassfifier = adaboost(DecisionTreeClassifier(max_depth = 1).fit(X_train,y_train), n_estimators= i, random_state = 0) \n",
    "    scores = cross_val_score(adaclassfifier, X, y, cv = 5)\n",
    "    print(\"n_estmators = %d, 'Accuracy: %.3f, %.3f'\" % (i, mean(scores), std(scores)))\n",
    "    accuracy_ada.append(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b89343",
   "metadata": {},
   "source": [
    "Using cross-validation, increasing the number of estimators in the bagging classifier improved the model's performance from 0.640 to 0.927. In the case of the ada boosting classifier, increasing the number of estimators caused accuracy to fluctuate, with the final accuracy being somewhat lower than when only one estimator was used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
