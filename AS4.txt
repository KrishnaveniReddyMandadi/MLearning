Step 1: Create a synthetic dataset using "sklearn.datasets.make_classification". https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html (Links to an external site.). In this, you can set the following parameters for the dataset. n_samples=10000, n_features=20, n_informative=10, n_redundant=2, n_classes=2. That is, we are creating a dataset for binary classification with 10K samples, 20 features where there are only 10 informative features, 2 features are redundant ones (combinations of informative features) and the rest 20-10-2 = 8 features are just random noise.

Step 2: Evaluate 5-fold cross validation performance on the synthetic dataset for the NNet classifier. "sklearn.neural_network.MLPClassifier". Here you can set the network structure using hidden_layer_sizes. For example, hidden_layer_sizes=(10,) means there is a single hidden layer with 10 units. Also, you can change the activation functions for the units using  the "activation" parameter. Experiment with different settings (1 hidden layer, 2 hidden layer with varying number of hidden nodes..there is no standard way to do this but just trial and error!) for which the performance seems reasonably good.

Step 3: Increase the number of noisy features in the data by decreasing n_informative in Step 1 and generate  2 other synthetic datasets with different number of n_informative features. Apply the evaluation in step 2 (no need to change the neural network architecture at this point but just use the one that gave you best performance with the first dataset). How did the Neural Network performance change as the number of noisy features in the dataset increased? You can report the average 5-fold cross validation scores to compare the performance.